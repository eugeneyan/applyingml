{
    "componentChunkName": "component---src-templates-post-js",
    "path": "/resources/personalization/",
    "result": {"data":{"mdx":{"frontmatter":{"title":"Patterns for Personalization in RecSys and Search","description":"A whirlwind tour of bandits, embedding + MLP, sequences, graph, and user embeddings.","name":null,"role":null,"slug":"/resources/personalization/","type":"resource"},"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Patterns for Personalization in RecSys and Search\",\n  \"description\": \"A whirlwind tour of bandits, embedding + MLP, sequences, graph, and user embeddings.\",\n  \"date\": \"2021-06-16\",\n  \"slug\": \"/resources/personalization/\",\n  \"type\": \"resource\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Personalization is the process of customizing each individual\\u2019s experience. It\\u2019s how an electronics geek gets different recommendations from a cooking hobbyist, and how they might get different results from the same search query (e.g., \\u201CApple\\u201D)\"), mdx(\"p\", null, \"How does personalization happen? I dug into a couple of industry papers and bucketed them into a few groups (e.g., bandit, sequential, graph-based). These groups aren\\u2019t mutually exclusive, and some approaches fall into multiple buckets. Nonetheless, they\\u2019re a good overview of the various patterns for personalization.\"), mdx(\"h2\", {\n    \"id\": \"bandits-learning-continuously-via-exploration\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Bandits: Learning continuously via exploration\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#bandits-learning-continuously-via-exploration\",\n    \"aria-label\": \"bandits learning continuously via exploration permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"Multi-armed bandits try to balance exploration and exploitation. They explore new actions to learn what the potential reward is, and they exploit the current best action to maximize reward. The goal is to learn about and choose actions that maximize total reward (aka minimize regret).\"), mdx(\"p\", null, \"Contextual bandits take it a step further, where they collect and observe the context before each action, and choose actions based on the context. They learn about how actions \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"and context\"), \" affect reward. In the case of recommendations and search, the context would be information we have about the customer (e.g., demographics, device, indicated/historical preferences) and environment (e.g., day of week, time of day).\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"59.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAEDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAd5TCwg//8QAFxAAAwEAAAAAAAAAAAAAAAAAAAEREP/aAAgBAQABBQLYQSh//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGxAAAgMAAwAAAAAAAAAAAAAAAAERITEQUXH/2gAIAQEAAT8he1Q9nH3w7HpkCj//2gAMAwEAAgADAAAAECPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxAAAgMAAwAAAAAAAAAAAAAAAREAITFRYeH/2gAIAQEAAT8QfRmLTfUFKNIFGE+IMgCdnSYvpAIZN3P/2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"The difference between multi-armed and contextual bandits\",\n    \"title\": \"The difference between multi-armed and contextual bandits\",\n    \"src\": \"/static/ab58fc7714ce05b133a63f412a3239c3/29d31/contextual-bandit.jpg\",\n    \"srcSet\": [\"/static/ab58fc7714ce05b133a63f412a3239c3/e52aa/contextual-bandit.jpg 175w\", \"/static/ab58fc7714ce05b133a63f412a3239c3/70ebb/contextual-bandit.jpg 350w\", \"/static/ab58fc7714ce05b133a63f412a3239c3/29d31/contextual-bandit.jpg 700w\", \"/static/ab58fc7714ce05b133a63f412a3239c3/4b190/contextual-bandit.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"The difference between multi-armed and contextual bandits\",\n    source: \"https://dl.acm.org/doi/10.1145/3240323.3240354\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"Bandits have several advantages over batch machine learning approaches. Relative to batch ML models and A/B tests, a bandit-based approach has lower regret. Regret happens when customers are not able to benefit from a better model, such as when the data\\u2019s being collected (before the model can be trained), or when the customer is not in the best treatment group in an A/B test. Bandits don\\u2019t need to collect a full batch of data, train a model, and wait for an A/B test to conclude\\u2014instead, they can continuously learn about the best recommendation for each customer through exploration. \"), mdx(\"p\", null, \"In some cases, they may behave more optimally than batch recommenders. Batch recommenders tend to perform well when we have high certainty about recommendation relevance, such as when we have a lot of data about the user-item pair. However, when we have little or no data (i.e., long-tail, cold-start), batch recommenders ignore possibly relevant items in favor of popular items. In contrast, bandit recommenders can continue to explore in the face of uncertainty and gather more data.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Netflix shared how they use contextual bandits to \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://netflixtechblog.com/artwork-personalization-c589f074ad76\"\n  }, \"personalize images for shows\"), \".\"), \" The bandit can choose from a set of images for each show (i.e., action) and observe the number of minutes the user played the show after being impressed with the image (i.e., reward). It also has information about user attributes (e.g., titles played, genres played, country, language preferences), day of week, time of day, etc. (i.e., context). \"), mdx(\"p\", null, \"For offline evaluation of the bandit, they apply \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"replay\"), \" on the bandit\\u2019s predicted image and the random image shown during the exploration phase. They first get the bandit\\u2019s predicted image for each user-show pair. Then, they try to match it with the random images shown to users in the exploration phase. If the predicted image matches the randomly assigned image, that predicted-random match can be used for evaluation.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"32.57142857142857%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIEBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHXrkSB/8QAFxABAAMAAAAAAAAAAAAAAAAAAAMSIf/aAAgBAQABBQKRlX//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwFX/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAgEFAAAAAAAAAAAAAAAAADEBA0JRgZH/2gAIAQEABj8Ch6L1kVTp/8QAHRAAAQIHAAAAAAAAAAAAAAAAADFBAREhgaHR8P/aAAgBAQABPyHPcTYW7Uiq1uz/2gAMAwEAAgADAAAAEAw//8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQMBAT8Qqn//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPxCI/8QAHBABAAEEAwAAAAAAAAAAAAAAAREAITFBUaHB/9oACAEBAAE/EHBMd2E1uXFJHhEhJft5TJ6BcIwU/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"How to compute replay using random and model predicted images\",\n    \"title\": \"How to compute replay using random and model predicted images\",\n    \"src\": \"/static/ee6bb5742a11013f9891a505088a2ee7/29d31/replay-netflix.jpg\",\n    \"srcSet\": [\"/static/ee6bb5742a11013f9891a505088a2ee7/e52aa/replay-netflix.jpg 175w\", \"/static/ee6bb5742a11013f9891a505088a2ee7/70ebb/replay-netflix.jpg 350w\", \"/static/ee6bb5742a11013f9891a505088a2ee7/29d31/replay-netflix.jpg 700w\", \"/static/ee6bb5742a11013f9891a505088a2ee7/4b190/replay-netflix.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"How to compute replay using random and model predicted images\",\n    source: \"https://netflixtechblog.com/artwork-personalization-c589f074ad76\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"From the set of predicted-random matches, they check if the user played the title or not. The main metric of interest is the number of quality plays over the number of impressions (i.e., take fraction)\\u2014for the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"n\"), \" images that were recommended, how many resulted in the user watching the show?\"), mdx(\"p\", null, \"The benefit of replay is that it\\u2019s an unbiased metric when accounting for the probability of each image shown during exploration. Having the probability allows us to weigh the reward to control for bias in image display rates, either in exploration or production. (Also see this \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.cs.cornell.edu/~adith/CfactSIGIR2016/\"\n  }, \"SIGIR tutorial on counterfactual evaluation\"), \".) The downside is that it requires a lot of data, and there could be high variance in evaluation metrics if there are few matches between the predicted and random data. Nonetheless, techniques such as \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1103.4601\"\n  }, \"doubly robust estimation\"), \" can help.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Doordash also adopted a contextual bandit approach for \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://doordash.engineering/2020/01/27/personalized-cuisine-filter/\"\n  }, \"cuisine recommendations\"), \", with the addition of multiple geolocation levels.\"), \" The bandit explores by suggesting new cuisine types to customers to gauge their interest, and exploits to recommend customers their most preferred cuisines.\"), mdx(\"p\", null, \"To model the \\u201Caverage\\u201D cuisine preference in each location, they introduced multiple levels in their bandit. As an example, they shared how levels could go from the lowest level of district, through submarket, market, and region.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"41.142857142857146%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAID/8QAFgEBAQEAAAAAAAAAAAAAAAAABAEC/9oADAMBAAIQAxAAAAHcHfYuf//EABcQAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQEAAQUChMSP/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Bp//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABUQAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEBAAY/Am//xAAZEAACAwEAAAAAAAAAAAAAAAAAAREhMUH/2gAIAQEAAT8hvg2lLhBKo//aAAwDAQACAAMAAAAQ+D//xAAWEQADAAAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8Qobp//8QAFhEBAQEAAAAAAAAAAAAAAAAAABEB/9oACAECAQE/EJiP/8QAGxABAAIDAQEAAAAAAAAAAAAAARExAFFhcSH/2gAIAQEAAT8Qgkj5KVvzECIYRVM8wihbmvM//9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"The multiple levels in Doordash's multi-level bandit\",\n    \"title\": \"The multiple levels in Doordash's multi-level bandit\",\n    \"src\": \"/static/2ba77712cdd925f2ac7eab24acfb23f9/29d31/multi-level-bandit.jpg\",\n    \"srcSet\": [\"/static/2ba77712cdd925f2ac7eab24acfb23f9/e52aa/multi-level-bandit.jpg 175w\", \"/static/2ba77712cdd925f2ac7eab24acfb23f9/70ebb/multi-level-bandit.jpg 350w\", \"/static/2ba77712cdd925f2ac7eab24acfb23f9/29d31/multi-level-bandit.jpg 700w\", \"/static/2ba77712cdd925f2ac7eab24acfb23f9/4b190/multi-level-bandit.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"The multiple levels in Doordash's multi-level bandit\",\n    source: \"https://doordash.engineering/2020/01/27/personalized-cuisine-filter/\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"Each geolocation level provides prior knowledge so that cold-start customers can be represented by the prior of the location, until the bandit collects enough data about them for personalization. The geolocation priors also allows Doordash to balance the customer's existing preferences with the hot favorites of each geolocation. A sushi-lover ordering food from a new geolocation may be exposed to the hot favorite in the area (e.g., fried chicken), balancing his preferences with local popularity.\"), mdx(\"p\", null, \"As a final example, we look at \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"how Spotify using contextual bandits to \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/3240323.3240354\"\n  }, \"identify the best recommendation explanation\"), \" (aka \\u201Crecsplanations\\u201D) for users.\"), \" The problem was how to jointly personalize music recommendations with their associated explanation, where the reward is user engagement on the recommendation. Contextual features include user region, product and platform of user device, user listening history (genres, playlist), etc.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"48.57142857142858%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB27RQf//EABgQAAIDAAAAAAAAAAAAAAAAAAABEDFB/9oACAEBAAEFAmYqhH//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAZEAACAwEAAAAAAAAAAAAAAAAAERAhMWH/2gAIAQEAAT8hZ8LZmE4P/9oADAMBAAIAAwAAABADz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQADAAIDAAAAAAAAAAAAAAEAESEQMUFRYf/aAAgBAQABPxAhWPpUBMKzPDDX0LjuOkVe+D//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"The various recsplanations in Spotify\",\n    \"title\": \"The various recsplanations in Spotify\",\n    \"src\": \"/static/b5ad155bef8abf095c4844873dd03cea/29d31/recsplanations.jpg\",\n    \"srcSet\": [\"/static/b5ad155bef8abf095c4844873dd03cea/e52aa/recsplanations.jpg 175w\", \"/static/b5ad155bef8abf095c4844873dd03cea/70ebb/recsplanations.jpg 350w\", \"/static/b5ad155bef8abf095c4844873dd03cea/29d31/recsplanations.jpg 700w\", \"/static/b5ad155bef8abf095c4844873dd03cea/4b190/recsplanations.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"The various recsplanations in Spotify\",\n    source: \"https://dl.acm.org/doi/10.1145/3240323.3240354\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"An initial approach involved using logistic regression to predict user engagement from a recsplanation, given data about the recommendation, explanation, and user context. However, for logistic regression, the recsplanation that maximized reward was the same regardless of the user context.\"), mdx(\"p\", null, \"To address this, they introduced higher-order interactions between recommendation, explanation, and user context, first by embedding them, and then introducing inner products on the embeddings (i.e., 2nd-order interactions). Then, the 2nd-order interactions are combined with first-order variables via a weighted sum, making it a 2nd-order factorization machine. They tried both 2nd and 3rd order factorization machines. (For more details of factorization machines in recommendations, see figure 2 and the \\u201CFM Component\\u201D section in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1703.04247\"\n  }, \"DeepFM\"), \" paper).\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"49.142857142857146%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHs3Vgqv//EABcQAQEBAQAAAAAAAAAAAAAAAAEQAiH/2gAIAQEAAQUCXpqN/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAERQVEx/9oACAEBAAE/IUppNLFwsYQf/9oADAMBAAIAAwAAABCvz//EABURAQEAAAAAAAAAAAAAAAAAABAR/9oACAEDAQE/EKf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAdEAEAAgICAwAAAAAAAAAAAAABACERMUFxgbHB/9oACAEBAAE/EM/1TgHXggU1Lm35UY5HubdYhmm4AKCf/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"The factorization machine component of DeepFM; note the addition and inner products\",\n    \"title\": \"The factorization machine component of DeepFM; note the addition and inner products\",\n    \"src\": \"/static/cd7efd5e4054c68a6b2339e7fa0907e4/29d31/deepfm_fm.jpg\",\n    \"srcSet\": [\"/static/cd7efd5e4054c68a6b2339e7fa0907e4/e52aa/deepfm_fm.jpg 175w\", \"/static/cd7efd5e4054c68a6b2339e7fa0907e4/70ebb/deepfm_fm.jpg 350w\", \"/static/cd7efd5e4054c68a6b2339e7fa0907e4/29d31/deepfm_fm.jpg 700w\", \"/static/cd7efd5e4054c68a6b2339e7fa0907e4/4b190/deepfm_fm.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"The factorization machine component of DeepFM\",\n    source: \"https://arxiv.org/abs/1703.04247\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"To train their model, they adopt sample reweighting to account for the non-uniform probability of recommendations in production. (They didn\\u2019t have the benefit of uniform random samples like in the Netflix example.) During offline evaluation, the 3rd-order factorization machine performed best. During online evaluation (i.e., A/B test), both 2nd and 3rd-order factorization machines did better than logistic regression and the baseline. Nonetheless, there was no significant difference between the 2nd and 3rd-order models.\"), mdx(\"h2\", {\n    \"id\": \"embeddingmlp-learning-embeddings-pooling-them\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Embedding+MLP: Learning embeddings; pooling them\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#embeddingmlp-learning-embeddings-pooling-them\",\n    \"aria-label\": \"embeddingmlp learning embeddings pooling them permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"Deep learning has increasingly been applied to recommendations and search. In the beginning, they mostly adopted an embedding + multilayer perceptron (MLP) paradigm.\"), mdx(\"p\", null, \"First, sparse input features (e.g., item, customer, context) are mapped into embedding vectors. Features that are variable in length, such as sequences of user historical behavior, are transformed into fixed-size vectors, usually via mean, sum, or max pooling. Then, the various features are concatenated and fed into full connected layers. The recommendation task is typically posed as a classification problem, with a final softmax layer predicting each item\\u2019s probability, or a final sigmoid layer predicting user engagement on an item (e.g., click, purchase).\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TripAdvisor shared about how they recommend \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://www.tripadvisor.com/engineering/personalized-recommendations-for-experiences-using-deep-learning/\"\n  }, \"personalized experiences\"), \" (i.e., tours) via this paradigm.\"), \" The recommender predicts the user\\u2019s next interest in an experience given her browsing history.\"), mdx(\"p\", null, \"First, they train general-purpose item embeddings (100-dim) using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1709.03856\"\n  }, \"StarSpace\"), \", based on page view data. These embeddings are consumed by other downstream tasks, such as home page recommendations and ranking. Specific for personalized experiences, the embeddings are used to initialize the model weights before being fine-tuned for the specific recommendation task.\"), mdx(\"p\", null, \"The model takes user browsing history as input. However, browsing history could be of varying lengths for different users. To compress them into a fix-length vector, they apply exponential recency weighted average. This is based on the assumption that the most recent browsing data would contribute most to predicting the next action. (They also tried using an LSTM to combine the embeddings but didn\\u2019t see any improvements relative to the recency weighted average.)\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"40.57142857142858%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIDBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAC/9oADAMBAAIQAxAAAAHWuETC/wD/xAAXEAADAQAAAAAAAAAAAAAAAAAAATEC/9oACAEBAAEFAncw/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQMBAT8BJ//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAEQIaH/2gAIAQEABj8Ch1//xAAZEAACAwEAAAAAAAAAAAAAAAAAEQExofH/2gAIAQEAAT8hjXQJ0xH/2gAMAwEAAgADAAAAEPgP/8QAFREBAQAAAAAAAAAAAAAAAAAAEDH/2gAIAQMBAT8Qs//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQEAAgMBAAAAAAAAAAAAAAERACExUfBx/9oACAEBAAE/EEZ5WTdfdZoA2cxQ/XI85//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"TripAdvisor's MLP for personalized experience recommendations\",\n    \"title\": \"TripAdvisor's MLP for personalized experience recommendations\",\n    \"src\": \"/static/5cb1ef07da807259e6a9cda25683c77f/29d31/tripadvisor-model.jpg\",\n    \"srcSet\": [\"/static/5cb1ef07da807259e6a9cda25683c77f/e52aa/tripadvisor-model.jpg 175w\", \"/static/5cb1ef07da807259e6a9cda25683c77f/70ebb/tripadvisor-model.jpg 350w\", \"/static/5cb1ef07da807259e6a9cda25683c77f/29d31/tripadvisor-model.jpg 700w\", \"/static/5cb1ef07da807259e6a9cda25683c77f/4b190/tripadvisor-model.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"TripAdvisor's MLP for personalized experience recommendations\",\n    source: \"https://www.tripadvisor.com/engineering/personalized-recommendations-for-experiences-using-deep-learning/\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"The averaged embeddings then pass through two ReLU layers (2048-dim, 512-dim) before a final softmax layer to predict the probability over 64,000 experiences. While they found that increasing the dimensions of the hidden layers led to improved accuracy, it also increased serving latency. The penultimate layer of 512-dim was a trade-off between accuracy and latency.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"YouTube adopts a similar approach for \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://research.google/pubs/pub45530/\"\n  }, \"video recommendations\"), \", though they split the process into candidate generation and ranking.\")), mdx(\"p\", null, \"In the candidate generation stage, to represent user interests, they used the user\\u2019s past searches (i.e., search query token embeddings) and watches (i.e., video embeddings). To combine these variable-length sequences into a fixed-sized vector, they applied mean pooling. (They also tried other strategies such as sum, component-wise max, etc., and found mean pooling to work best). Then, they concatenate other user features such as geography, demographics, as well as the age of the video (to represent freshness). The demographic variables provide useful priors in the case of cold-start users.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"74.85714285714286%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe7Oiwf/xAAYEAACAwAAAAAAAAAAAAAAAAABEAACQv/aAAgBAQABBQIwFaqv/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGhAAAgMBAQAAAAAAAAAAAAAAAREAECFhcf/aAAgBAQABPyE+xh10z4jEbX//2gAMAwEAAgADAAAAEIPP/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Qp//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQADAQADAAAAAAAAAAAAAAEAESExYXGh/9oACAEBAAE/EAKGnqLwAc8kESzkSe4o+Mo7t4pAqf/Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"YouTube's candidate generation model for video recommendations\",\n    \"title\": \"YouTube's candidate generation model for video recommendations\",\n    \"src\": \"/static/4701cd3b879fd445dd8a0106eaf2564e/29d31/youtube-retrieval.jpg\",\n    \"srcSet\": [\"/static/4701cd3b879fd445dd8a0106eaf2564e/e52aa/youtube-retrieval.jpg 175w\", \"/static/4701cd3b879fd445dd8a0106eaf2564e/70ebb/youtube-retrieval.jpg 350w\", \"/static/4701cd3b879fd445dd8a0106eaf2564e/29d31/youtube-retrieval.jpg 700w\", \"/static/4701cd3b879fd445dd8a0106eaf2564e/4b190/youtube-retrieval.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"YouTube's candidate generation model for video recommendations\",\n    source: \"https://research.google/pubs/pub45530/\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"The features then pass through several fully connected ReLUs before a final softmax that predicts the probability of each video being watched. Given that there are millions of potential videos to predict the probability of, they adopt negative sampling to train the model efficiently. In practice, several thousand negatives are sampled, which led to a more than 100x speedup over the traditional softmax.\"), mdx(\"p\", null, \"During serving, they apply approximate nearest neighbors to find video candidates for each user embedding. (Aside: I\\u2019m not sure what the arrow of video vectors pointing out of the softmax are. I\\u2019m guessing that, to get these video embeddings, they simply pass the single video as the watch vector and leave the other features empty. If you have a better understanding, please \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://twitter.com/eugeneyan\"\n  }, \"reach out\"), \".)\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"61.142857142857146%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe9Giwf/xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAQUCFP8A/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGhABAQEAAwEAAAAAAAAAAAAAAQARITFhcf/aAAgBAQABPyFck7yMOy6/Lo32DC//2gAMAwEAAgADAAAAEOMP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARITFxgf/aAAgBAQABPxAw4vhNesYVAFkZD4nEdYCgn//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"YouTube's ranking model for video recommendations\",\n    \"title\": \"YouTube's ranking model for video recommendations\",\n    \"src\": \"/static/f48e994892c6fb7444fd1ebeaa1afcab/29d31/youtube-ranking.jpg\",\n    \"srcSet\": [\"/static/f48e994892c6fb7444fd1ebeaa1afcab/e52aa/youtube-ranking.jpg 175w\", \"/static/f48e994892c6fb7444fd1ebeaa1afcab/70ebb/youtube-ranking.jpg 350w\", \"/static/f48e994892c6fb7444fd1ebeaa1afcab/29d31/youtube-ranking.jpg 700w\", \"/static/f48e994892c6fb7444fd1ebeaa1afcab/4b190/youtube-ranking.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"YouTube's ranking model for video recommendations\",\n    source: \"https://research.google/pubs/pub45530/\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"The ranking stage follows a similar approach. Video embeddings are averaged and concatenated with other features. The input also includes the video candidate to be impressed (from the previous candidate generation step); see the leftmost feature in the diagram above. This is then passed through several ReLU layers before a final sigmoid layer that predicts the probability of the video being watched, weighted by the observed watch time. The output is a list of candidates and their predicted watch time, which is then used to rank the videos.\"), mdx(\"p\", null, \"As a final example, we look at \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Alibaba\\u2019s \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://arxiv.org/abs/1706.06978\"\n  }, \"Deep Interest Network\"), \" for predicting ad engagement.\"), \" The authors assert that one downside of neural recommenders is the compression of variable-length behaviors into fixed-length vectors via pooling (e.g., mean, sum, max). As a result, it makes it difficult to understand and capture the user\\u2019s diverse interests effectively. (To recap, TripAdvisor used recency weighted mean while YouTube used simple mean.)\"), mdx(\"p\", null, \"To improve on this, they introduced an attention layer that weighs historical user behavior using attention. The intent is to learn different representations of the user\\u2019s interest given the candidate ad. The model builds on their base model which was inspired by YouTube\\u2019s video recommender. The attention layer is introduced between the embedding and pooling layer, helping the model to learn which events are more important, and weigh them accordingly. (Similar to TripAdvisor, the authors also tried using an LSTM to model user historical behavior but it didn\\u2019t help). \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"36%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3oFB/8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQABBQJ//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAFxABAQEBAAAAAAAAAAAAAAAAAQARIf/aAAgBAQABPyHXZexf/9oADAMBAAIAAwAAABBzz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABkQAAMBAQEAAAAAAAAAAAAAAAERIQAxUf/aAAgBAQABPxCSTzEpc5cyJMZe/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Baseline model (left); Deep Interest Network with attention layer (right)\",\n    \"title\": \"Baseline model (left); Deep Interest Network with attention layer (right)\",\n    \"src\": \"/static/eb23943f8347605d261ca00c099d65d7/29d31/alibaba-din.jpg\",\n    \"srcSet\": [\"/static/eb23943f8347605d261ca00c099d65d7/e52aa/alibaba-din.jpg 175w\", \"/static/eb23943f8347605d261ca00c099d65d7/70ebb/alibaba-din.jpg 350w\", \"/static/eb23943f8347605d261ca00c099d65d7/29d31/alibaba-din.jpg 700w\", \"/static/eb23943f8347605d261ca00c099d65d7/4b190/alibaba-din.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Baseline model (left); Deep Interest Network with attention layer (right)\",\n    source: \"https://arxiv.org/abs/1706.06978\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"In offline evaluation, the deep interest network had a 2% AUC improvement over the base model. In online evaluation, there was a click-through rate improvement of 10% and a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Revenue_per_mille\"\n  }, \"revenue per mille\"), \" improvement of 3.8%.\"), mdx(\"p\", null, \"(Trivia: This paper was published on arXiv on 21 June 2017 while the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1706.03762\"\n  }, \"Transformer\"), \" paper (i.e., Attention is all you need) was published on 12 Jun 2017. It seems both groups were working on the concept of attention from neural machine translation, though for different use cases (ads and language translation). Goes to show that methods in machine learning can be applied across varying domains.)\"), mdx(\"h2\", {\n    \"id\": \"sequential-learning-about-item-order-in-a-sequence\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Sequential: Learning about item order in a sequence\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#sequential-learning-about-item-order-in-a-sequence\",\n    \"aria-label\": \"sequential learning about item order in a sequence permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"An alternative to pooling variable-length user behavior events is to use sequential models such as RNNs. Nonetheless, one downside of RNN is that its input cannot be processed in a parallel manner\\u2014each event in the sequence requires the hidden state of the previous event. The recent NLP breakthrough, Transformer, addresses this by introducing positional encodings to help the model learn about each event\\u2019s order in the sequence. \"), mdx(\"p\", null, \"Let\\u2019s first look at an RNN-based approach. \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Researchers from Telefonica experimented with using GRUs for \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://arxiv.org/abs/1511.06939\"\n  }, \"session-level recommendations\"), \".\"), \" They shared that most real-world recommendations don\\u2019t have the benefit of long user histories (e.g., Netflix) and can only work with short, session-level data. Thus, they sought to model user sessions for more relevant recommendations.\"), mdx(\"p\", null, \"Their model uses a single \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Gated_recurrent_unit\"\n  }, \"GRU\"), \" layer (additional layers led to worse results) followed by multiple fully connected layers. (They also tried using RNN and LSTM; both performed worse.) The final layer was a softmax over the catalog of items, limited to the most popular 30k - 40k items to reduce training and prediction time. \"), mdx(\"p\", null, \"The input is the current event in the session while the output is the next event (i.e., the initial input to the GRU is the first item that the user interacts with on the website in a session). Each subsequent event is passed through the GRU and the hidden state of one time-step is used as input to the (same) hidden layer of the next time-step. This allows the model to learn the temporal relationships between events in user behavioral sequences. They also tried passing \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"all\"), \" previous events in the session as the input (instead of just the current event) but it didn\\u2019t lead to additional accuracy gain, suggesting the GRU\\u2019s ability to remember and account for previous events.\"), mdx(\"p\", null, \"The input is represented via one-hot encoding (using item embeddings led to worse results). The output predicts the likelihood of each item in the catalog being the next item in the session. In offline evaluation, they showed that their GRU-based recommender outperformed item-KNN (based on co-occurrence of items in each session). \"), mdx(\"p\", null, \"As a continuation of their previous work on attention (i.e., deep interest network), \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Alibaba proposed using the Transformer encoder block to model variable-length user behavior.\"), \" They call it \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1905.06874\"\n  }, \"Behavioral Sequence Transformer\"), \" (BST). Similar to Deep Interest Networks (DIN), the paper focuses on the ranking stage, where given a set of candidate items, BST predicts the probability of clicking an item given the user\\u2019s historical behavior. \"), mdx(\"p\", null, \"Input items are represented by item and item-category embeddings. Though each item can have up to hundreds of features, it was too expensive (i.e., training time and inference latency) to include more in the behavioral sequence. The target item (i.e., each candidate from the candidate retrieval step) is included as part of the input, likely its position set to zero so BST can learn that it\\u2019s the target item. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"61.71428571428571%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe9FI0P/xAAXEAADAQAAAAAAAAAAAAAAAAAAARAR/9oACAEBAAEFAojL/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGBAAAwEBAAAAAAAAAAAAAAAAAAERITH/2gAIAQEAAT8hbFmMRwiMl04f/9oADAMBAAIAAwAAABCjz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAQACAwEAAAAAAAAAAAAAAAEAESExUUH/2gAIAQEAAT8QEGr9jQorCZt57cdB2Aot4gAon//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Alibaba's behavioral sequence transformer\",\n    \"title\": \"Alibaba's behavioral sequence transformer\",\n    \"src\": \"/static/3a90cd26eb2eeab3093faa01c3987b56/29d31/alibaba-bst.jpg\",\n    \"srcSet\": [\"/static/3a90cd26eb2eeab3093faa01c3987b56/e52aa/alibaba-bst.jpg 175w\", \"/static/3a90cd26eb2eeab3093faa01c3987b56/70ebb/alibaba-bst.jpg 350w\", \"/static/3a90cd26eb2eeab3093faa01c3987b56/29d31/alibaba-bst.jpg 700w\", \"/static/3a90cd26eb2eeab3093faa01c3987b56/4b190/alibaba-bst.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Alibaba's behavioral sequence transformer\",\n    source: \"https://arxiv.org/abs/1905.06874\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"For positional encodings, instead of using sin and cosine functions (like in the Transformer paper), they represented position (\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"pos\"), \") by time difference between previous item interactions and recommendation time. They found this to work better than the original sinusoidal encodings. Another deviation is that while the original Transformer summed the input embeddings with the position embeddings, BST concatenates them instead.\"), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-display\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\",\n    \"display\": \"block\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"normal\"\n  }, \"pos\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2061\"), mdx(\"mrow\", {\n    parentName: \"mrow\"\n  }, mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \"(\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"i\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \")\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"t\"), mdx(\"mrow\", {\n    parentName: \"mrow\"\n  }, mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \"(\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"t\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \")\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2212\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"t\"), mdx(\"mrow\", {\n    parentName: \"mrow\"\n  }, mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \"(\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"i\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \")\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\operatorname{pos}\\\\left(v_{i}\\\\right)=t\\\\left(v_{t}\\\\right)-t\\\\left(v_{i}\\\\right)\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mop\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathrm\"\n  }, \"p\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathrm\"\n  }, \"o\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathrm\"\n  }, \"s\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"minner\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.31166399999999994em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"i\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \")\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"t\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"minner\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.2805559999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"t\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \")\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mbin\"\n  }, \"\\u2212\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"t\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"minner\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.31166399999999994em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"i\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \")\"))))))), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-display\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\",\n    \"display\": \"block\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"t\"), mdx(\"mrow\", {\n    parentName: \"mrow\"\n  }, mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \"(\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"t\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \")\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mtext\", {\n    parentName: \"mrow\"\n  }, \"recommendation\\xA0time\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"t\\\\left(v_{t}\\\\right) = \\\\text{recommendation time}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"t\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"minner\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.2805559999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"t\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \")\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.69444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord text\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"recommendation\\xA0time\"))))))), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-display\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\",\n    \"display\": \"block\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"t\"), mdx(\"mrow\", {\n    parentName: \"mrow\"\n  }, mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \"(\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"i\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"fence\": \"true\"\n  }, \")\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mtext\", {\n    parentName: \"mrow\"\n  }, \"timestamp\\xA0when\\xA0user\\xA0clicked\\xA0on\\xA0\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \"(\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"i\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \")\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"t\\\\left(v_{i}\\\\right) = \\\\text{timestamp when user clicked on }(v_{i})\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"t\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"minner\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.31166399999999994em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"i\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose delimcenter\",\n    \"style\": {\n      \"top\": \"0em\"\n    }\n  }, \")\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord text\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"timestamp\\xA0when\\xA0user\\xA0clicked\\xA0on\\xA0\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.31166399999999994em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"i\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose\"\n  }, \")\")))))), mdx(\"p\", null, \"They used a single transformer encoder block (using two or three led to worse results\\u2014overfitting?) The output of the transformer block is then concatenated with embeddings of other features (e.g., user profile, item, context). It then goes through three fully connected layers before a final sigmoid layer which predicts whether the item will be clicked or not.\"), mdx(\"p\", null, \"How does using attention compare to pooling? They created a variant of Wide and Deep Learning which incorporates using history via mean pooling (WDL+Seq). From the results, we see that BST has a 4.5% CTR gain over mean pooling of behavioral sequences (WDL+Seq), and a 3% CTR gain over the previous DIN. Nonetheless, we should note that it also increases latency by 33% (from 15ms to 20ms). Alibaba has since shared about applying other sequential models for recommendations such as \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.06690\"\n  }, \"BERT4Rec\"), \".\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"38.857142857142854%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAdm4SD//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAEFAn//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAY/An//xAAZEAEAAgMAAAAAAAAAAAAAAAABABExceH/2gAIAQEAAT8hMG5RfYBU/9oADAMBAAIAAwAAABDzz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAAICAwEAAAAAAAAAAAAAAAERACExQZGh/9oACAEBAAE/EEJLvzA6wFqBsB2f/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Results comparing BST to WDL with averaged sequences (WDL+Seq) and DIN\",\n    \"title\": \"Results comparing BST to WDL with averaged sequences (WDL+Seq) and DIN\",\n    \"src\": \"/static/b8bf3c663efdad842b422679e4f6034c/29d31/alibaba-bst-results.jpg\",\n    \"srcSet\": [\"/static/b8bf3c663efdad842b422679e4f6034c/e52aa/alibaba-bst-results.jpg 175w\", \"/static/b8bf3c663efdad842b422679e4f6034c/70ebb/alibaba-bst-results.jpg 350w\", \"/static/b8bf3c663efdad842b422679e4f6034c/29d31/alibaba-bst-results.jpg 700w\", \"/static/b8bf3c663efdad842b422679e4f6034c/4b190/alibaba-bst-results.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Results comparing BST to WDL with averaged sequences (WDL+Seq) and DIN\",\n    source: \"https://arxiv.org/abs/1905.06874\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"Finally, let\\u2019s look at \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Spotify\\u2019s approach to \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://research.atspotify.com/publications/contextual-and-sequential-user-embeddings-for-large-scale-music-recommendation/\"\n  }, \"learn on sequences of sessions\"), \" to derive session-level user embeddings.\"), \" Each session consists of multiple music tracks. The intent is to learn a personalized user embedding for the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"next\"), \" session, given historical sessions and the current session's context. The model is trained to maximize cosine similarity between the predicted session-level user embedding, and the actual session-level user embedding (computed from what the user actually plays).\"), mdx(\"p\", null, \"First, track embeddings are learned using word2vec via the continuous bag of words paradigm. Each session is then represented by the average of all tracks it contains. To better learn user preferences, they created three types of session embeddings: all tracks in the session, played tracks, and skipped tracks. \"), mdx(\"p\", null, \"In addition to the session embedding, they also concatenate features about the context (e.g., day of week, time of day, device) and the previous session (e.g., number of tracks played, time since last session). Then, to learn across multiple sessions, they use an LSTM where the output and hidden state from each session is used to predict the next session. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"40%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3AWD/8QAFRABAQAAAAAAAAAAAAAAAAAAEEH/2gAIAQEAAQUCp//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAABD/2gAIAQEABj8Cf//EABcQAQEBAQAAAAAAAAAAAAAAAAEAQTH/2gAIAQEAAT8hU1ZHL//aAAwDAQACAAMAAAAQgA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAACAgMAAAAAAAAAAAAAAAAAAREhUWGh/9oACAEBAAE/EIxpK2T1kZQtH//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Spotify's model to learn user-level session embeddings from past sessions\",\n    \"title\": \"Spotify's model to learn user-level session embeddings from past sessions\",\n    \"src\": \"/static/d0e72eae55538eb86b37acb81ce313d1/29d31/spotify-model.jpg\",\n    \"srcSet\": [\"/static/d0e72eae55538eb86b37acb81ce313d1/e52aa/spotify-model.jpg 175w\", \"/static/d0e72eae55538eb86b37acb81ce313d1/70ebb/spotify-model.jpg 350w\", \"/static/d0e72eae55538eb86b37acb81ce313d1/29d31/spotify-model.jpg 700w\", \"/static/d0e72eae55538eb86b37acb81ce313d1/4b190/spotify-model.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Spotify's model to learn user-level session embeddings from past sessions\",\n    source: \"https://research.atspotify.com/publications/contextual-and-sequential-user-embeddings-for-large-scale-music-recommendation/\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"Finally, they combine the predicted session-level user embedding with the long-term user embedding (weighted average of previous session embeddings), by learning attention weights on the LSTM output. Session-level user embeddings that are uncertain can thus default to the long-term user embedding. (It\\u2019s unclear how much of the juice is due to the LSTM on session sequences relative to the long-term user embedding). \"), mdx(\"h2\", {\n    \"id\": \"graph-learning-from-a-user-or-items-neighbors\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Graph: Learning from a user or item's neighbors\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#graph-learning-from-a-user-or-items-neighbors\",\n    \"aria-label\": \"graph learning from a user or items neighbors permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"Beyond representing users and their past behaviors as sequences, we can also represent them as graphs. For example, a user-item graph has users, and items that users have previously interacted with, as nodes. Edges can be weighted by the number of past interactions, item ratings, etc. \"), mdx(\"p\", null, \"The graph captures user interests as well as structural information about the user\\u2019s neighborhood (e.g., other users who also interacted with the same items, and the other items they interacted with). Thus, a user\\u2019s neighbors can help enrich what we know about the user when user behavior is sparse. The same goes for item nodes.\"), mdx(\"p\", null, \"There are various ways to learn on a graph, including \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1403.6652\"\n  }, \"DeepWalk\"), \", \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1607.00653\"\n  }, \"Node2Vec\"), \", and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1803.02349\"\n  }, \"learning embeddings from an item graph\"), \". These approaches generally convert the graph into a sequence (via random walks) before applying unsupervised or semi-supervised sequential models; we won\\u2019t cover those here. In this section, we\\u2019ll focus on approaches that apply graph convolutions networks (CGN). Here\\u2019s a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://towardsdatascience.com/graph-convolutional-networks-deep-99d7fee5706f\"\n  }, \"short primer\"), \" on how CGNs work. \"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Uber shared about how they apply \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://eng.uber.com/uber-eats-graph-learning/\"\n  }, \"CGNs for food recommendations\"), \".\"), \" They start by building two bipartite graphs. The first has users and dishes as nodes, and edges are weighted by the number of times a user ordered a dish, as well as the user rating on the dish. The second graph represents users and restaurants as nodes, where edges are the number of items ordered from a restaurant. \"), mdx(\"p\", null, \"They adopt \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://snap.stanford.edu/graphsage/\"\n  }, \"GraphSAGE\"), \" for the CGN, where the aggregation function is a mean or max pooling after projection. They also use sampling to constrain the number of nodes sampled to reduce computation required. (Pinterest also uses a variant called \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1806.01973\"\n  }, \"PinSage\"), \" for item-to-item recommendations.)\"), mdx(\"p\", null, \"Dishes are represented by embeddings of the description and images, while restaurants are represented by features related to menu and cuisine offerings. Given that there are different features for users, dishes, and restaurants, each node type will have different embedding dimensions. Thus, they use a projection layer to project all node embeddings to the same dimension.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"42.857142857142854%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHtOrMxB//EABoQAAICAwAAAAAAAAAAAAAAAAABEBEhMkH/2gAIAQEAAQUCqzqwLaP/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAVEAEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAQAGPwJrf//EABwQAAEDBQAAAAAAAAAAAAAAAAABEbEQMUFRcf/aAAgBAQABPyFNiBrs9GIIFFP/2gAMAwEAAgADAAAAEMPP/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQMBAT8QJ//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAECAQE/EEn/xAAcEAEAAwACAwAAAAAAAAAAAAABABEhMVEQocH/2gAIAQEAAT8QChtg49GNcHFcuoaAO7qs9H68cp//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Ubereats' two-part hinge loss to account for strong and weak edges\",\n    \"title\": \"Ubereats' two-part hinge loss to account for strong and weak edges\",\n    \"src\": \"/static/36e566c2e826dc8535300d9de12868d6/29d31/ubereats-hinge-loss.jpg\",\n    \"srcSet\": [\"/static/36e566c2e826dc8535300d9de12868d6/e52aa/ubereats-hinge-loss.jpg 175w\", \"/static/36e566c2e826dc8535300d9de12868d6/70ebb/ubereats-hinge-loss.jpg 350w\", \"/static/36e566c2e826dc8535300d9de12868d6/29d31/ubereats-hinge-loss.jpg 700w\", \"/static/36e566c2e826dc8535300d9de12868d6/4b190/ubereats-hinge-loss.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Ubereats' two-part hinge loss to account for strong and weak edges\",\n    source: \"https://eng.uber.com/uber-eats-graph-learning/\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"While GraphSAGE only considers binary edges, Uber\\u2019s user-dish and user-restaurant graphs have weighted edges, such as the number of times a user ordered a dish, as well as the user rating. To account for this, they adopted a two-part hinge loss. The hinge loss ensures that the predicted score between strong edges (i.e., multiple food orders) is higher than weak edges (i.e., few food orders), and the score on weak edges is higher than non-edges by a certain margin. (This is similar to the three-part hinge loss in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/resources/search-query-matching/\"\n  }, \"Amazon\\u2019s semantic product search\"), \".)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Alibaba also shared about their \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://arxiv.org/abs/2103.16164\"\n  }, \"graph intention network\"), \" for ad prediction.\"), \" They use session-level user clicks to build the user-item graph, where edges are weighed by the co-occurrence of items clicked in the same session.\"), mdx(\"p\", null, \"To learn a user\\u2019s intention for personalization, they apply diffusion and aggregation on the user-item graph. In the diffusion step, for each item the user has previously interacted with, they retrieve the neighboring users and their items. Then, in the aggregation step, they apply attention that considers correlations between the current node and its neighbors (see bottom half of image below).\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"57.14285714285714%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3QVR/8QAFRABAQAAAAAAAAAAAAAAAAAAESD/2gAIAQEAAQUCa//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABoQAAICAwAAAAAAAAAAAAAAAAABEDERIWH/2gAIAQEAAT8hyOiodMS3H//aAAwDAQACAAMAAAAQ8M//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEBAQADAQEAAAAAAAAAAAABEQAxUWEhcf/aAAgBAQABPxBBkOe8Krfyd6wQp64H6YlXzABDjf/Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Learning item embeddings via a graph and attention\",\n    \"title\": \"Learning item embeddings via a graph and attention\",\n    \"src\": \"/static/5122366b64ae17a17606ac9cabe70fe0/29d31/alibaba-gin.jpg\",\n    \"srcSet\": [\"/static/5122366b64ae17a17606ac9cabe70fe0/e52aa/alibaba-gin.jpg 175w\", \"/static/5122366b64ae17a17606ac9cabe70fe0/70ebb/alibaba-gin.jpg 350w\", \"/static/5122366b64ae17a17606ac9cabe70fe0/29d31/alibaba-gin.jpg 700w\", \"/static/5122366b64ae17a17606ac9cabe70fe0/4b190/alibaba-gin.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Learning item embeddings via a graph and attention\",\n    source: \"https://arxiv.org/abs/2103.16164\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"These graph embeddings are then combined via item-level attention and concatenated with features about the target item, user, query, and context. It then passes through multiple ReLUs before a sigmoid predicting probability of click. The entire model is trained end-to-end, including the graph embeddings and attention. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"65.71428571428571%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB0WUbDCSv/8QAGBAAAwEBAAAAAAAAAAAAAAAAAQIDEQD/2gAIAQEAAQUCuxC0fCm5WZx1J5VC9//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EAB0QAAICAgMBAAAAAAAAAAAAAAECABEhQRIxYYH/2gAIAQEABj8Ca+SgHsbiama+RirkExaaq8mJ/8QAGhABAQEBAQEBAAAAAAAAAAAAAREAMSFhcf/aAAgBAQABPyGJAU0E1ab+/Mku1etdQTvoYfsPeri0MFu//9oADAMBAAIAAwAAABB/D//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAAIDAAMBAAAAAAAAAAAAAAERACExQVFhcf/aAAgBAQABPxAsERJZbjwdwpM0C8a+wu1BCwJ0/YZicVHoVssEgJInq8jWxnbZOmf/2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Examples of similar vs. relevant relationships between products\",\n    \"title\": \"Examples of similar vs. relevant relationships between products\",\n    \"src\": \"/static/59235a11d709fd53651853d1c2a75ca5/29d31/alibaba-gin-relationships.jpg\",\n    \"srcSet\": [\"/static/59235a11d709fd53651853d1c2a75ca5/e52aa/alibaba-gin-relationships.jpg 175w\", \"/static/59235a11d709fd53651853d1c2a75ca5/70ebb/alibaba-gin-relationships.jpg 350w\", \"/static/59235a11d709fd53651853d1c2a75ca5/29d31/alibaba-gin-relationships.jpg 700w\", \"/static/59235a11d709fd53651853d1c2a75ca5/4b190/alibaba-gin-relationships.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Examples of similar vs. relevant relationships between products\",\n    source: \"https://arxiv.org/abs/2103.16164\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"They shared that representing items via a graph reveals two types of item relationships. First, there are groups of highly similar items. These homogenous groups help enrich user interests when behavioral data is sparse. Second, there are pairs of relevant but less similar items. This helps introduce serendipity and exploration based on a user\\u2019s past interest. \"), mdx(\"h2\", {\n    \"id\": \"user-embeddings-learning-a-model-of-the-user\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"User embeddings: Learning a model of the user\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#user-embeddings-learning-a-model-of-the-user\",\n    \"aria-label\": \"user embeddings learning a model of the user permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"Finally, other than representing users as a sequence or graph of their past behavior, we can also learn user embeddings directly. \"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Airbnb shared their approach to learning user type embeddings for \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/3219819.3219885\"\n  }, \"search result personalization\"), \".\"), \" One problem they faced was data sparsity. Unlike retail e-commerce where customers shop and purchase weekly or monthly, user behavior on travel accommodations tends to be less frequent, maybe once or twice a year. Thus, they didn\\u2019t have enough data to learn user-level embeddings. Instead, they learn user-type embeddings based on location, device type, language settings, guest settings, number of past bookings, average price, etc.\"), mdx(\"p\", null, \"These user-type embeddings are learned by interleaving them with session-level behavioral data (in which users interact with Airbnb listings) and applying a word2vec-like skip-gram model (pretty smart and lean IMO). This ensures that the user-type embeddings are in the same vector space as the listing embeddings, while still allowing them to use a self-supervised approach without needing labels. \"), mdx(\"p\", null, \"To use these user-type embeddings in search ranking, they compute the cosine similarity between user-type and candidate listings and add it as a feature. They shared that these (long-term) user-type embeddings had higher feature importance than the (short-term) user history feature which was based on bookings in the last two weeks. This is likely because the user-type embedding had higher coverage (86%) relative to the short-term user history feature (8%). \"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Alibaba also incorporates \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://arxiv.org/abs/1904.06813\"\n  }, \"user embeddings in the ranking stage\"), \" to account for user preferences.\"), \" To learn user embeddings, they train a fully connected model that takes as input the user\\u2019s behavior history, user features (e.g., gender, age, price level), and each candidate item. The final layer is a sigmoid predicting click probability on each item. User embeddings are then represented by the hidden vector (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pv\"), \") from the penultimate layer. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"500px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"102.85714285714288%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAVABQDASIAAhEBAxEB/8QAGQABAQADAQAAAAAAAAAAAAAAAAIBAwQF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAgAB/9oADAMBAAIQAxAAAAH3onUF1BmcGVjb/8QAGRABAAMBAQAAAAAAAAAAAAAAAQACEBIx/9oACAEBAAEFAoQ8vaDjUXnP/8QAFREBAQAAAAAAAAAAAAAAAAAAEiD/2gAIAQMBAT8BMf/EABgRAAIDAAAAAAAAAAAAAAAAAAEQAhEh/9oACAECAQE/ATLVS//EAB4QAAAFBQEAAAAAAAAAAAAAAAABEEGRAhEhMTKB/9oACAEBAAY/Ag6Wx6Y5plNEGhP/xAAcEAADAAIDAQAAAAAAAAAAAAAAAREhQTFRYXH/2gAIAQEAAT8hfAzjcw09jWpPBS2+QJPCDyUDZ9RPQI//2gAMAwEAAgADAAAAELDH/P/EABYRAQEBAAAAAAAAAAAAAAAAAAEQEf/aAAgBAwEBPxASbNZ//8QAGBEAAgMAAAAAAAAAAAAAAAAAEBFRsfD/2gAIAQIBAT8QQmoJA//EABoQAQEBAAMBAAAAAAAAAAAAAAERACExUUH/2gAIAQEAAT8QFfKPp3rw6GIY5Jt+uzBiUeUMeYqtD8vCCiI9Jgzw4Yq4EgbbQdYAQADzf//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Learning personalized vectors given user's history, candidate item, and user profile\",\n    \"title\": \"Learning personalized vectors given user's history, candidate item, and user profile\",\n    \"src\": \"/static/6d29a6f16494e53f89a889e6c507653c/41099/alibaba-user-model.jpg\",\n    \"srcSet\": [\"/static/6d29a6f16494e53f89a889e6c507653c/e52aa/alibaba-user-model.jpg 175w\", \"/static/6d29a6f16494e53f89a889e6c507653c/70ebb/alibaba-user-model.jpg 350w\", \"/static/6d29a6f16494e53f89a889e6c507653c/41099/alibaba-user-model.jpg 500w\"],\n    \"sizes\": \"(max-width: 500px) 100vw, 500px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Learning personalized vectors given user history, candidate item, user profile\",\n    source: \"https://arxiv.org/abs/1904.06813\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"To use the personalized vector (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pv\"), \"), they concatenate it with candidate item embeddings (see image below). This is then put through attention layers before predicting the probability of click on each candidate item. Each item\\u2019s score is then used for reranking.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"54.85714285714286%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHttyKK/8QAFhAAAwAAAAAAAAAAAAAAAAAAASAx/9oACAEBAAEFAjV//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGxAAAgEFAAAAAAAAAAAAAAAAAAEhEBExQVH/2gAIAQEAAT8hZ7CzPBUspEf/2gAMAwEAAgADAAAAEJvP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhABAAIDAQAAAAAAAAAAAAAAAQARITFBUf/aAAgBAQABPxAFTCnsSm2bKX24lG4GTLt7Hl6Qb3v2f//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"The personalized vectors (`pv`) are concatenated with candidate item embeddings\",\n    \"title\": \"The personalized vectors (`pv`) are concatenated with candidate item embeddings\",\n    \"src\": \"/static/de8e156673c630b81842c59a2729ae5b/29d31/alibaba-reranker.jpg\",\n    \"srcSet\": [\"/static/de8e156673c630b81842c59a2729ae5b/e52aa/alibaba-reranker.jpg 175w\", \"/static/de8e156673c630b81842c59a2729ae5b/70ebb/alibaba-reranker.jpg 350w\", \"/static/de8e156673c630b81842c59a2729ae5b/29d31/alibaba-reranker.jpg 700w\", \"/static/de8e156673c630b81842c59a2729ae5b/4b190/alibaba-reranker.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"The personalized vectors (pv) are concatenated with candidate items\",\n    source: \"https://arxiv.org/abs/1904.06813\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"As a final example, we look at \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Tencent\\u2019s approach to learning \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://arxiv.org/abs/1906.05022\"\n  }, \"user lookalikes for long-tail content recommendations\"), \" on WeChat.\"), \" WeChat is a messaging app in China that provides personalized articles, news, and videos via a \\u201CTop Stories\\u201D widget. Due to recommender feedback loops, popular content gets recommended to a greater extent and becomes more popular. As a result, content that is high quality and relevant, but less popular, languishes in the long-tail. This leads to reduced diversity and possibly stale recommendations.\"), mdx(\"p\", null, \"To address the lack of behavioral data on long-tail content, Tencent developed a user-lookalike model for recommendations. Given a target user, who are the users that look like them, and what (long-tail) content have they viewed? Then, recommend the target user content from their lookalikes (i.e., user-user recommendations).\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"49.71428571428571%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3TCgf/xAAYEAACAwAAAAAAAAAAAAAAAAAAARARQf/aAAgBAQABBQLSxT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAaEAACAgMAAAAAAAAAAAAAAAABEQAQITFh/9oACAEBAAE/IWDwoCnQM0NT/9oADAMBAAIAAwAAABCDD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB0QAQACAgIDAAAAAAAAAAAAAAEAESFRMbFBkcH/2gAIAQEAAT8QzhlcCt1csK1PBUAnD6hAoDH2AU413McNvc//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Tencent's model to learn user embeddings based on their past behavior\",\n    \"title\": \"Tencent's model to learn user embeddings based on their past behavior\",\n    \"src\": \"/static/5b256a05d2316cc4fd74aec4fe856216/29d31/tencent-user-model.jpg\",\n    \"srcSet\": [\"/static/5b256a05d2316cc4fd74aec4fe856216/e52aa/tencent-user-model.jpg 175w\", \"/static/5b256a05d2316cc4fd74aec4fe856216/70ebb/tencent-user-model.jpg 350w\", \"/static/5b256a05d2316cc4fd74aec4fe856216/29d31/tencent-user-model.jpg 700w\", \"/static/5b256a05d2316cc4fd74aec4fe856216/4b190/tencent-user-model.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Tencent's model to learn user embeddings based on their past behavior\",\n    source: \"https://arxiv.org/abs/1906.05022\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"To learn user embeddings, they adopt an approach similar to YouTube\\u2019s ranking model. For the model\\u2019s input, they pass the user features (e.g., demographics, user indicated interests, follows, etc.) and historical behavior on WeChat. For labels, they use content that the user has clicked on, and adopt a negative sampling ratio of 10:1. Then, given the user and item embeddings, they put it through a dot product followed by a sigmoid to predict clicks. The model is trained and the user embedding is applied to represent users.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"100%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe7IWCdDAf/EABkQAQEBAAMAAAAAAAAAAAAAAAARAQIQQf/aAAgBAQABBQK9RqMcnkf/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAWEAEBAQAAAAAAAAAAAAAAAAAgETH/2gAIAQEABj8CGw//xAAbEAADAAMBAQAAAAAAAAAAAAAAAREhQWExUf/aAAgBAQABPyHC1pfB53SDtI1a6QZT0WoSKhSs/9oADAMBAAIAAwAAABCwBzz/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAdEAEAAwACAwEAAAAAAAAAAAABABEhMUFRYXGR/9oACAEBAAE/EGwfYbKsL05Ag5Yc+2BdyuPdRuIfBspcceZQCpvTOBb+zIYeWf/Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Tencent's two-tower lookalike model learn global and local attention on lookalikes\",\n    \"title\": \"Tencent's two-tower lookalike model learn global and local attention on lookalikes\",\n    \"src\": \"/static/5eced8eb2d82642995ef754f2928b971/29d31/tencent-lookalike-model.jpg\",\n    \"srcSet\": [\"/static/5eced8eb2d82642995ef754f2928b971/e52aa/tencent-lookalike-model.jpg 175w\", \"/static/5eced8eb2d82642995ef754f2928b971/70ebb/tencent-lookalike-model.jpg 350w\", \"/static/5eced8eb2d82642995ef754f2928b971/29d31/tencent-lookalike-model.jpg 700w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Tencent's two-tower lookalike model learn global and local attention\",\n    source: \"https://arxiv.org/abs/1906.05022\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"To learn lookalikes, they use a two-tower model to learn similarities between the target user embedding and the lookalike user embedding. Given that the number of lookalike users can be very large (as many as three million), instead of using user-level lookalike embeddings, they apply K-means clustering and use the centroids instead. They found K = 20 to work best. \"), mdx(\"p\", null, \"The input for the two-tower model is the user-lookalike pair, where the user embedding and lookalike embedding are passed into separate towers. The model includes a global and local attention mechanism. Global attention models how to weigh each lookalike (e.g., reduce weight of noisy users). Local attention models how to weigh each lookalike while considering the interest of the target user, thus learning a personalized representation. At the top of the two-tower model, the dot product is used to represent the similarity between the target and lookalikes. This is a proxy for the target user\\u2019s interest in the long-tail content that the lookalikes interacted with.\"), mdx(\"p\", null, \"In production, the global and local attention transforms each lookalike embedding into global and local embeddings before being summed. The global embedding has 0.7 weight while the local embedding has 0.3 weight. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"45.142857142857146%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAQACBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe4IbiP/xAAVEAEBAAAAAAAAAAAAAAAAAAAQAf/aAAgBAQABBQJr/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAERITEQcf/aAAgBAQABPyGZ2n6UJmuLD//aAAwDAQACAAMAAAAQ4M//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEAAwACAwAAAAAAAAAAAAABABExIUFxgcH/2gAIAQEAAT8QtkAZNmmxA4V+wQ4qvMwnfqYT/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Tencent's overall system design for long-tail recommendations using user lookalikes\",\n    \"title\": \"Tencent's overall system design for long-tail recommendations using user lookalikes\",\n    \"src\": \"/static/d4472a5ac07326613f3c78e1c200b452/29d31/tencent-overall-system.jpg\",\n    \"srcSet\": [\"/static/d4472a5ac07326613f3c78e1c200b452/e52aa/tencent-overall-system.jpg 175w\", \"/static/d4472a5ac07326613f3c78e1c200b452/70ebb/tencent-overall-system.jpg 350w\", \"/static/d4472a5ac07326613f3c78e1c200b452/29d31/tencent-overall-system.jpg 700w\", \"/static/d4472a5ac07326613f3c78e1c200b452/4b190/tencent-overall-system.jpg 800w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Tencent's system design for long-tail recs using user lookalikes\",\n    source: \"https://arxiv.org/abs/1906.05022\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"Here\\u2019s the overall system design, where the user representations and lookalike model are learned offline (bottom third of item) before being used online to compute similarities for recommendations. The top third of the image shows how the K-means clustering is applied on lookalikes every five minutes to get the 20 lookalike candidates.\"), mdx(\"h2\", {\n    \"id\": \"conclusion\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Conclusion\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#conclusion\",\n    \"aria-label\": \"conclusion permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"That was a whirlwind tour of the various patterns for personalization in recommendations and search. These patterns are not exhaustive. I\\u2019ve also come across papers that add \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1904.08030\"\n  }, \"multi-interest\"), \" \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2005.09347\"\n  }, \"heads\"), \" and learn \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://dl.acm.org/doi/abs/10.1145/3336191.3371827\"\n  }, \"interest hierarchies\"), \" on top of user interests, as well as approaches to model user interest \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.02974\"\n  }, \"across domains\"), \". When to use which? Here's a rough heuristic:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Want to continuously explore while minimizing regret? Bandits\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Starting with neural recsys & want something simple? Embeddings+MLP\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Have long-term user histories and sequences? Sequential\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Have sparse behavior data but lots of item/user metadata? Graphs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Want generic embeddings for multiple problems? User models\")), mdx(\"p\", null, \"If you\\u2019re starting with personalization, good ol\\u2019 logistic regression with crossed features is a tough baseline to beat. If you\\u2019re building a \", \"[real-time recommender]\", \"({{ site.baseurl }}{% link posts/_posts/2021-01-10-real-time-recommendations.md %}#how-to-design-and-implement-an-mvp) (i.e., generates recs on request), learning item embeddings via word2vec and applying approximate nearest neighbors is pretty lean and gets much of the juice from session-level behavioral data. \"), mdx(\"h2\", {\n    \"id\": \"references\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"References\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#references\",\n    \"aria-label\": \"references permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://netflixtechblog.com/artwork-personalization-c589f074ad76\"\n  }, \"Artwork Personalization at Netflix\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Netflix\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://doordash.engineering/2020/01/27/personalized-cuisine-filter/\"\n  }, \"Personalized Cuisine Filter\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"DoorDash\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/3240323.3240354\"\n  }, \"Explore, Exploit, and Explain: Explainable Recommendations with Bandits\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Spotify\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.tripadvisor.com/engineering/personalized-recommendations-for-experiences-using-deep-learning/\"\n  }, \"Personalized Recommendations for Experiences Using Deep Learning\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"TripAdvisor\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.google/pubs/pub45530/\"\n  }, \"Deep Neural Networks for YouTube Recommendations\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Google\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.06978\"\n  }, \"Deep Interest Network for Click-Through Rate Prediction\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Alibaba\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1511.06939\"\n  }, \"Session-based Recommendations with Recurrent Neural Networks\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Telefonica\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1905.06874\"\n  }, \"Behavior Sequence Transformer for E-commerce Recommendation\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Alibaba\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://research.atspotify.com/publications/contextual-and-sequential-user-embeddings-for-large-scale-music-recommendation/\"\n  }, \"Contextual & Sequential User Embeddings for Music Recommendation\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Spotify\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://eng.uber.com/uber-eats-graph-learning/\"\n  }, \"Food Discovery with Uber Eats: Graph Learning to Power Recommendations\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Uber\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"%60https://arxiv.org/abs/2103.16164%60\"\n  }, \"Graph Intention Network for CTR Prediction in Sponsored Search\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Alibaba\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/3219819.3219885\"\n  }, \"Real-time Personalization using Embeddings for Search Ranking\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Airbnb\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.06813\"\n  }, \"Personalized Re-ranking for Recommendation\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Alibaba\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1906.05022\"\n  }, \"Real-time Attention Based Look-alike Model for Recommender System\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Tencent\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.cs.cornell.edu/~adith/CfactSIGIR2016/\"\n  }, \"SIGIR 2016 Tutorial on Counterfactual Evaluation and Learning\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1103.4601\"\n  }, \"Doubly Robust Policy Evaluation and Learning\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1703.04247\"\n  }, \"DeepFM: A Factorization-Machine based Neural Network for CTR Prediction\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1709.03856\"\n  }, \"StarSpace: Embed All The Things!\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1706.03762\"\n  }, \"Attention Is All You Need\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1904.06690\"\n  }, \"BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1403.6652\"\n  }, \"DeepWalk: Online Learning of Social Representations\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1607.00653\"\n  }, \"Node2vec: Scalable Feature Learning for Networks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1803.02349\"\n  }, \"Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://snap.stanford.edu/graphsage/\"\n  }, \"GraphSAGE: Inductive Representation Learning on Large Graphs\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1806.01973\"\n  }, \"Graph Convolutional Neural Networks for Web-Scale Recommender Systems\"))));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"slug":"/resources/personalization/"}},
    "staticQueryHashes": ["3159585216","3897982121"]}