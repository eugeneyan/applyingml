{
    "componentChunkName": "component---src-templates-post-js",
    "path": "/resources/bandits/",
    "result": {"data":{"mdx":{"frontmatter":{"title":"Bandits for Recommender Systems","description":"Industry examples, exploration strategies, warm-starting, off-policy evaluation, and more.","name":null,"role":null,"slug":"/resources/bandits/","type":"resource"},"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Bandits for Recommender Systems\",\n  \"description\": \"Industry examples, exploration strategies, warm-starting, off-policy evaluation, and more.\",\n  \"date\": \"2022-05-08\",\n  \"slug\": \"/resources/bandits/\",\n  \"type\": \"resource\",\n  \"homepage\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Recommender systems work well when we have a lot of data on user-item preferences. With a lot of data, we have high certainty about what users like. Conversely, with very little data, we have low certainty. Despite the low certainty, recommenders tend to greedily promote items that received higher engagement in the past. And because they influence how much exposure an item gets, potentially relevant items that aren\\u2019t recommended continue getting no to low engagement, perpetuating the feedback loop.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Bandits address this by modeling uncertainty and exploration.\"), \" By acknowledging the uncertainty in the data and deliberately exploring to reduce it, bandits learn about the relevance of unexplored items. \"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"This is especially applicable when the item set changes quickly\"), \", such as for news, ads, and tweets, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"or when the rate of traffic is low.\"), \" If new items are constantly added, waiting to collect batch data before retraining the model can be too slow. Bandits are a good fit as they can incrementally update with new data and adaptively focus on items with higher reward. This reduces regret, which is the opportunity cost while recommending suboptimal items.\"), mdx(\"h2\", {\n    \"id\": \"ε-greedy-ucb-and-thompson-sampling\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"\\u03B5-greedy, UCB, and Thompson Sampling\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#%CE%B5-greedy-ucb-and-thompson-sampling\",\n    \"aria-label\": \"ε greedy ucb and thompson sampling permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"We\\u2019ll briefly discuss three main bandit algorithms before looking at some industrial implementations of each. Here are a few terms I use throughout: (i) action/arm: recommendation candidates, (ii) reward: customer interaction from a single trial, such as a click or purchase, (iii) value: estimated long-term reward of an arm over multiple trials, and (iv) policy: algorithm/agent that chooses actions based on learned values.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u03B5-greedy is the classic bandit algorithm.\"), \" At every trial, it randomly chooses an action with probability \\u03B5 and greedily chooses the highest value action with probability 1 - \\u03B5. We balance the explore-exploit trade-off via the parameter \\u03B5. A higher \\u03B5 leads to more exploration while a lower \\u03B5 leads to more exploitation. However, \\u03B5-greedy can explore longer than necessary (though this can be mediated by decreasing \\u03B5 over time). Another downside is that \\u03B5-greedy doesn\\u2019t provide guidance on which items to explore and defaults to exploring all items uniformly at random.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Upper Confidence Bound (UCB) considers the uncertainty\"), \" of an arm and selects arms that have the highest potential. Uncertainty is modeled \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"via confidence bounds\"), \" while potential is represented by the upper confidence bound (thus the name of the algorithm). Because of how it works, UCB is often referred to as \\u201Coptimism in the face of uncertainty\\u201D.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"45.142857142857146%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3lBR/8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQABBQJf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGRAAAwADAAAAAAAAAAAAAAAAAAEQETFB/9oACAEBAAE/Id8EYin/2gAMAwEAAgADAAAAECAP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBABAAIBBQAAAAAAAAAAAAAAAQAxEBEhQWGR/9oACAEBAAE/EHgrbuHQp9gCsUx//9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Example of UCB with a frequently tried arm (green) and a rarely tried arm (red)\",\n    \"title\": \"Example of UCB with a frequently tried arm (green) and a rarely tried arm (red)\",\n    \"src\": \"/static/6080a6efd5f43f4816ea7efd9c59e1c8/29d31/ucb.jpg\",\n    \"srcSet\": [\"/static/6080a6efd5f43f4816ea7efd9c59e1c8/e52aa/ucb.jpg 175w\", \"/static/6080a6efd5f43f4816ea7efd9c59e1c8/70ebb/ucb.jpg 350w\", \"/static/6080a6efd5f43f4816ea7efd9c59e1c8/29d31/ucb.jpg 700w\", \"/static/6080a6efd5f43f4816ea7efd9c59e1c8/9ecec/ucb.jpg 1050w\", \"/static/6080a6efd5f43f4816ea7efd9c59e1c8/e5166/ucb.jpg 1200w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Example of UCB with a frequently tried arm (green) and a rarely tried arm (red)\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"In the image above, \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Q\\u209C(a)\"), \" is the estimated value of arm \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"a\"), \" at time step \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"t\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"N\\u209C(a)\"), \" is the number of times arm \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"a\"), \" was selected, and \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"c\"), \" is a confidence parameter (which defaults to 1). The green arm has been chosen frequently and thus has narrower confidence bounds. In contrast, the red arm hasn\\u2019t been selected as often and thus has wider confidence bounds. When selecting an action, even though the green arm has a higher estimated value, the red arm has a higher UCB and is thus chosen. As the red arm is selected more, its confidence bounds will shrink. If the estimated value stays the same, its UCB will decrease to below the UCB of the green arm and the green arm will be chosen.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Thomson Sampling models uncertainty by building a probability distribution\"), \" from historical rewards and then samples from the distribution when choosing actions. In the simple case where rewards are binary, a Beta distribution is used. The Beta distribution takes two parameters, \\u03B1 and \\u03B2, and the mean value of the distribution is \\u03B1/\\u03B1 + \\u03B2 which can be thought of as successes / successes + failures. To select an action, we sample from each arm\\u2019s Beta distribution and choose the arm with the highest sampled values.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"61.142857142857146%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIDBAX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHeUiLAgf/EABkQAAIDAQAAAAAAAAAAAAAAAAABAhASIf/aAAgBAQABBQIXaZGOa//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAABEDH/2gAIAQEABj8CHdc//8QAGRABAQEAAwAAAAAAAAAAAAAAAQARITFh/9oACAEBAAE/IQmLwzJ63LQpyW3/2gAMAwEAAgADAAAAEMTP/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Qh//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAAIDAQEAAAAAAAAAAAAAAAERACExYaH/2gAIAQEAAT8QCi7d3AWESvMmoRQuhAtdpkF+RyA5/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Beta distributions that get narrower as α and β increase\",\n    \"title\": \"Beta distributions that get narrower as α and β increase\",\n    \"src\": \"/static/3241afc303454b89521d0a45a8945e2f/29d31/beta-distribution.jpg\",\n    \"srcSet\": [\"/static/3241afc303454b89521d0a45a8945e2f/e52aa/beta-distribution.jpg 175w\", \"/static/3241afc303454b89521d0a45a8945e2f/70ebb/beta-distribution.jpg 350w\", \"/static/3241afc303454b89521d0a45a8945e2f/29d31/beta-distribution.jpg 700w\", \"/static/3241afc303454b89521d0a45a8945e2f/9ecec/beta-distribution.jpg 1050w\", \"/static/3241afc303454b89521d0a45a8945e2f/e5166/beta-distribution.jpg 1200w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Beta distributions that get narrower as \\u03B1 and \\u03B2 increase\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"As we collect more data, \\u03B1 and \\u03B2 increase. As a result, the Beta distribution becomes narrower and we gain more certainty in our estimate of the arm\\u2019s value. The Beta distributions above all have the same mean of 0.5 though those with larger \\u03B1 and \\u03B2 are narrower. With a narrower distribution, our sampled values will be closer to the mean, thus reducing exploration and increasing exploitation.\"), mdx(\"h2\", {\n    \"id\": \"industry-examples-of-bandits-for-recsys\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Industry examples of bandits for recsys\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#industry-examples-of-bandits-for-recsys\",\n    \"aria-label\": \"industry examples of bandits for recsys permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An example of \\u03B5-greedy\"), \" is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/3240323.3240354\"\n  }, \"Spotify\\u2019s recplanations\"), \" (recommending explanations for music recommendations). They adopted \\u03B5-greedy for its simplicity of implementation in production and propensity scoring. To limit the negative impact of exploration on user experience, they pre-select 100 most relevant items to explore. These 100 items were selected via a separate embedding-based model that captured user preferences similar to the candidate selection stage of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/2959100.2959190\"\n  }, \"YouTube paper\"), \". \"), mdx(\"p\", null, \"Another example is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1809.02130\"\n  }, \"Schibsted\\u2019s multi-armed bandit ranker\"), \" which reranks candidate items from multiple sub-recommenders. For every input that is reranked, 5% random items are added to avoid local minima during training.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The classic example of UCB\"), \" is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1003.0146\"\n  }, \"Yahoo\\u2019s LinUCB for news recommendations\"), \". Ridge regression is trained to estimate reward linear on an arm\\u2019s features. The UCB is then derived by summing the predicted reward and the standard deviation of the ridge regression. A hybrid version of LinUCB also uses features that are shared by all arms (e.g., news category) and experiments showed that shared features allowed CTR information to be learned and exploited across multiple news articles.\"), mdx(\"p\", null, \"Another example is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.09368\"\n  }, \"Alibaba\\u2019s LinUCB for item recommendations\"), \" where they adopted the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/1390334.1390392\"\n  }, \"user browsing model\"), \" to add positional weights. The goal was to address position bias which has a strong influence on user engagement, especially on mobile surfaces. The positional weights modeled examination probability and the rewards for each arm are updated to consider both the arm\\u2019s features and examination probability. Similarly, ridge regression is applied and the standard deviation is used to compute the UCB.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"An example of Thompson Sampling\"), \" is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://doordash.engineering/2020/01/27/personalized-cuisine-filter/\"\n  }, \"Doordash\\u2019s bandits for cuisine recommendations\"), \". User preferences for a cuisine is modeled via Beta(\\u03B1=number of orders of the cuisine, \\u03B2=number of orders of other cuisines). When selecting a set of cuisine filters to show on the explore page, the value for each cuisine is sampled from the cuisine\\u2019s Beta distribution. These values are then sorted in descending order to select the top cuisines to display.\"), mdx(\"p\", null, \"Another example is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://papers.nips.cc/paper/2011/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html\"\n  }, \"Yahoo\\u2019s Thompson Sampling bandit for recommending ads and news\"), \". To predict the reward (i.e., CTR) of an ad or news article, they learned a regularized logistic regression model. Then, to model uncertainty, the posterior distribution of the model\\u2019s weights are represented by Gaussian distributions. For every trial, each weight is drawn independently from its Gaussian posterior distribution before being used to predict the reward of an action.\"), mdx(\"p\", null, \"A similar example is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1810.09558\"\n  }, \"Amazon\\u2019s multivariate bandits to optimize page layouts\"), \". Model weights are also represented and sampled from independent Gaussian distributions. However, because the decision space is so large due to the many layout combinations, they approximate argmax via greedy hill-climbing instead of an exhaustive search. Random restarts are included to alleviate suboptimal solutions.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Uncertainty can also be modeled via deep learning techniques.\"), \" \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.00727\"\n  }, \"Twitter\\u2019s deep learning bandit for ad recommendations\"), \" considered two approaches: bootstrapping and dropout.\"), mdx(\"p\", null, \"Bootstrapping models uncertainty by training multiple identical networks on different subsets of the data. However, this is costly as it requires partitioning and storing masks of the data, training multiple networks, and multiple forward passes across all networks. To reduce the computation cost, they used a multi-headed network that shares the same bottom layers and had each data subset pass through a different head during training.\"), mdx(\"p\", null, \"Dropout models uncertainty by having the network predict an action\\u2019s value via multiple forward passes with different dropout units. This is akin to sampling from the posterior distribution. The dropout layer acts as the heads of the multi-headed network.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"700px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"34.85714285714286%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3QUH/8QAFhABAQEAAAAAAAAAAAAAAAAAARAx/9oACAEBAAEFAmGf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAGBAAAwEBAAAAAAAAAAAAAAAAAAERITH/2gAIAQEAAT8hYbxUvo//2gAMAwEAAgADAAAAEPAP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGBABAAMBAAAAAAAAAAAAAAAAAQARQVH/2gAIAQEAAT8QUsEHLiUaMiQsL0n/2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Twitter's bayesian bandit which models uncertainty via a perultimate dropout layer\",\n    \"title\": \"Twitter's bayesian bandit which models uncertainty via a perultimate dropout layer\",\n    \"src\": \"/static/67b29456d79d748055c51aa4a6e27256/29d31/bayesian-bandit.jpg\",\n    \"srcSet\": [\"/static/67b29456d79d748055c51aa4a6e27256/e52aa/bayesian-bandit.jpg 175w\", \"/static/67b29456d79d748055c51aa4a6e27256/70ebb/bayesian-bandit.jpg 350w\", \"/static/67b29456d79d748055c51aa4a6e27256/29d31/bayesian-bandit.jpg 700w\", \"/static/67b29456d79d748055c51aa4a6e27256/9ecec/bayesian-bandit.jpg 1050w\", \"/static/67b29456d79d748055c51aa4a6e27256/e5166/bayesian-bandit.jpg 1200w\"],\n    \"sizes\": \"(max-width: 700px) 100vw, 700px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(FigureCaption, {\n    caption: \"Twitter's bayesian bandit which models uncertainty via a perultimate dropout layer\",\n    source: \"https://arxiv.org/abs/2008.00727\",\n    mdxType: \"FigureCaption\"\n  }), mdx(\"p\", null, \"Their eventual architecture used a dropout layer as the penultimate layer (right side of image above). When sampling from the posterior, they only needed to compute the bottom layers once before multiple passes through the dropout layer are done in parallel. The dropout layer provides a mask for each data point without having to explicitly partition the data set and also acts as the heads in a multi-headed network.\"), mdx(\"h2\", {\n    \"id\": \"lessons-on-applying-bandits-in-industry\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Lessons on applying bandits in industry\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#lessons-on-applying-bandits-in-industry\",\n    \"aria-label\": \"lessons on applying bandits in industry permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"First, UCB and Thompson Sampling \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://arxiv.org/abs/1003.0146\"\n  }, \"outperform \\u03B5-greedy\")), \". By default, \\u03B5-greedy is unguided and chooses actions uniformly at random. In contrast, UCB and Thompson Sampling are guided by confidence bounds and probability distributions that shrink as the action is tried more often. As a result, because UCB and Thompson Sampling smartly explore arms that have higher uncertainty, they have lower regret. \"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Second, when feedback is delayed, Thompson Sampling outperforms UCB.\"), \" Delayed feedback, where user-item interactions are not processed immediately, is common for most real-world systems due to resource and run-time constraints. In this situation, because UCB selects arms deterministically, it chooses the same action until new feedback is incorporated. In contrast, because Thompson Sampling chooses actions stochastically by sampling from the posterior distribution, it randomizes over actions even without updated rewards. \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://papers.nips.cc/paper/2011/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html\"\n  }, \"Yahoo\\u2019s evaluation of Thompson Sampling\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2009.06546\"\n  }, \"Deezer\\u2019s music bandit\"), \" observed that this led to wider exploration and thus better outcomes. \"), mdx(\"p\", null, \"To further study the impact of delayed rewards, Yahoo simulated different update delays of 10, 30, and 60 minutes. Thompson Sampling was competitive over all delays. On the other hand, while UCB outperformed Thompson Sampling when the delay was short (10 minutes), it performed worse than Thompson Sampling when the delay increased to 30 and 60 minutes. Overall, this suggests that stochastic policies are more robust to delay as they continue to explore even without updated rewards.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Third, how the bandit is initialized makes a difference.\"), \" \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2009.06546\"\n  }, \"Deezer\"), \" found that pessimistic initialization performed better than naive initialization. For Thompson Sampling, they experimented with naive initialization where the prior was Beta(1, 1) and pessimistic initialization where the prior was Beta(1, 99). Similar naive and pessimistic initialization was adopted for UCB. They found that pessimistic initialization performed better due to the lower prior probabilities which were more reflective of real-world reward.\"), mdx(\"h2\", {\n    \"id\": \"exploring-new-items---two-options\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Exploring new items - two options\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#exploring-new-items---two-options\",\n    \"aria-label\": \"exploring new items   two options permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"The few papers that discussed exploration adopted two main approaches: (i) \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"large exploration on a limited set of users\"), \" vs. (ii) \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"small exploration on all users\"), \".\"), mdx(\"p\", null, \"For the former, \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1003.0146\"\n  }, \"Yahoo uses an exploration bucket\"), \" that users are randomly selected into. Users in the exploration bucket are then served news articles uniformly at random. Similarly, \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.00727\"\n  }, \"Twitter has a random ad policy\"), \" that serves 1% of production traffic. \"), mdx(\"p\", null, \"For the latter, \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://netflixtechblog.com/artwork-personalization-c589f074ad76\"\n  }, \"Netflix tests new artwork on all users\"), \" (\\u201C\\u2026 the regret incurred by exploration is typically very small and is amortized across our large member base with each member implicitly helping provide feedback on artwork for a small portion of the catalog.\\u201D) Similarly, Schibsted adds 5% random items to every input of their bandit ranker.\"), mdx(\"h2\", {\n    \"id\": \"addressing-the-curse-of-dimensionality\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Addressing the curse of dimensionality\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#addressing-the-curse-of-dimensionality\",\n    \"aria-label\": \"addressing the curse of dimensionality permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"We can represent users via features such as gender, age group, location, behavior, etc. However, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"one concern with applying bandits conditioned on these features is the curse of dimensionality\"), \". More dimensions leads to less data for each combination of dimensions.\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1003.0146\"\n  }, \"Yahoo addressed this by applying PCA\"), \" for dimensionality reduction before learning a policy via LinUCB. They started with 1.2k user features (e.g., demographics, geolocation, and behavior). They also had 83 article features based on URL categories and editor categories. For feature reduction, they projected user features onto article features and then clustered users into five groups where users in each group had similar preferences. This reduced the 1.2k user features into five features. Article features were also reduced in a similar manner.\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2009.06546\"\n  }, \"Deezer compared\"), \" between representing users as clusters (semi-personalization) vs. user features (full personalization). For semi-personalization, users were clustered into 100 groups via k-means clustering on past behavior. This resulted in clusters of users with similar musical tastes. They then trained a separate bandit for each cluster. For full personalization, users were represented via a 97-dimension vector which summarizes user preferences for genres, moods, countries, etc. The vector was obtained by factorizing the user-song interaction matrix. They then trained a contextual bandit on these user features.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"The semi-personalized approach outperformed the fully personalized alternative.\"), \" Because the semi-personalized bandits were trained on user clusters, each bandit received more feedback and was thus able to learn more effectively and rank playlists faster.\"), mdx(\"h2\", {\n    \"id\": \"warm-starting-bandits-for-better-user-experience\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Warm-starting bandits for better user experience\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#warm-starting-bandits-for-better-user-experience\",\n    \"aria-label\": \"warm starting bandits for better user experience permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"To ensure our bandits provide a good user experience from the very first interaction\"), \", it\\u2019s typical to learn from previously logged user interactions to warm-start the bandit.\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://doordash.engineering/2020/01/27/personalized-cuisine-filter/\"\n  }, \"Doordash shared how they warm-start\"), \" their cuisine bandits via higher-level regional data. For each cuisine, they learn a bandit policy at multiple levels (i.e., regional, subregional, user). The top-level bandit is initialized at Beta(\\u03B1=1, \\u03B2=1). Then, for each lower-level bandit, they update \\u03B1 by adding the average number of orders for the cuisine (at that level) and update \\u03B2 by adding the average number of orders for other cuisines (at that level). Finally, for the user-level bandit, \\u03B1 and \\u03B2 are updated with the user\\u2019s order data. As a result, a new user\\u2019s cuisine bandit is warm-started with higher-level marketplace data before each new order updates the bandit with their personal preferences.\"), mdx(\"p\", null, \"Another approach is to warm-start user preferences using data collected via a random policy. \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1003.0146\"\n  }, \"Yahoo learned\"), \" user-specific CTR estimates (on random data) which were then added to context-free CTR estimates for news recommendations. They found that bandits warm-started with user preferences data were able to beat the context-free bandits.\"), mdx(\"p\", null, \"As an alternative to random data, this \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1003.0120\"\n  }, \"paper\"), \" showed how to warm-start bandits on data logged via the production policy by importance weighting it. The production policy (i.e., probability of each action) is required to importance weight logged events. To derive the production policy, they used empirical estimation. Specifically, for each ad and page pair, they computed the number of times an ad appeared on each page. This estimate is then used to importance weight logged events that the bandit learns on.\"), mdx(\"p\", null, \"Data collected via a greedy policy can also be helpful for warm-start. \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.00727\"\n  }, \"Twitter warm-started\"), \" their bandit on data collected by a greedy policy and found that warm-starting for more epochs (500 vs. 100) led to improved metrics on the test set.\"), mdx(\"h2\", {\n    \"id\": \"evaluating-bandits-via-off-policy-evaluation\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Evaluating bandits via off-policy evaluation\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#evaluating-bandits-via-off-policy-evaluation\",\n    \"aria-label\": \"evaluating bandits via off policy evaluation permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Several bandit implementations (e.g., Netflix, Yahoo) cite the \", mdx(\"a\", {\n    parentName: \"strong\",\n    \"href\": \"https://arxiv.org/abs/1003.5956\"\n  }, \"replay method by Li et al.\")), \" for off-policy evaluation. Replay assumes that (i) individual events are independently and identically distributed and (ii) the logging policy chose each arm uniformly at random. The paper then states that the latter assumption can be weakened so any randomized policy\\u2014not just uniform random\\u2014can be used. (My understanding is that randomness is required for sufficient support and thus uniform randomness isn\\u2019t strictly necessary.)\"), mdx(\"p\", null, \"During evaluation, replay takes in the new policy (to be evaluated) and the logged policy events. If the new policy chooses the same action as the logged policy, the event is added to the history and the reward is updated. If not, the event is ignored with no reward update. (\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/resources/counterfactual/\"\n  }, \"Counterfactual evaluation\"), \") via Inverse Propensity Scoring is another alternative.)\"), mdx(\"p\", null, \"How does bandit off-policy evaluation compare to typical supervised machine learning evaluation on logged data? \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.00727\"\n  }, \"Twitter\\u2019s paper\"), \" provides some insight. They computed two sets of metrics: (i) PR-AUC on a standard test set and (ii) CTR improvements vs. a random policy. There was a trade-off between PR-AUC and CTR. \"), mdx(\"p\", null, \"Although the greedy policy performed well on PR-AUC, it did relatively poorly on CTR. Conversely, bandit policies such as UCB and Thompson Sampling did poorer on PR-AUC but outperformed the greedy policy on CTR. This shows the divergence where \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"supervised learning that evaluates well on biased logged data via conventional metrics may not actually perform well on the metrics we really care about\"), \" (e.g., CTR, conversion).\"), mdx(\"h2\", {\n    \"id\": \"conclusion\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Conclusion\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#conclusion\",\n    \"aria-label\": \"conclusion permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"p\", null, \"Whew, that was a lot longer than the average post. If you\\u2019re still with me, I hope you found bandits to be a viable alternative for recommendation systems. Their focus on modeling uncertainty and deliberate exploration makes them effective when our data is small and we have low certainty on user-item preferences.\"), mdx(\"p\", null, \"Do you know of other industrial implementations of bandit-based recommendation systems? Please share them in the comments below!\"), mdx(\"h2\", {\n    \"id\": \"references\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"References\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#references\",\n    \"aria-label\": \"references permalink\",\n    \"className\": \"anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"height\": \"20px\",\n    \"width\": \"20px\",\n    \"style\": {\n      \"verticalAlign\": \"-10%\",\n      \"marginLeft\": \"0.25rem\"\n    },\n    \"fill\": \"#007bff\",\n    \"x\": \"0px\",\n    \"y\": \"0px\",\n    \"viewBox\": \"0 0 100 100\",\n    \"enableBackground\": \"new 0 0 100 52\",\n    \"xmlSpace\": \"preserve\"\n  }, mdx(\"g\", {\n    parentName: \"svg\",\n    \"transform\": \"matrix(0.6136733,-0.6136733,0.6136733,0.6136733,4.0598725,65.6509)\"\n  }, mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.807,33.138 c 0.008,-0.009 0.016,-0.019 0.024,-0.026 -0.009,0.007 -0.018,0.015 -0.026,0.023 0,0.001 10e-4,0.002 0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 53.048,49.8 c -0.274,-0.071 -0.545,-0.152 -0.815,-0.232 -0.002,0.001 -0.005,0.003 -0.007,0.003 0.259,0.077 0.534,0.155 0.822,0.229 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 36.33,35.501 h -0.004 c 0.204,0.522 0.496,1.114 0.783,1.651 h 0.013 c -0.284,-0.54 -0.548,-1.09 -0.792,-1.651 z\",\n    \"style\": {},\n    \"fill\": \"none\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.108,37.152 c 0.291,0.544 0.577,1.029 0.758,1.332 -0.263,-0.436 -0.508,-0.882 -0.746,-1.332 h -0.012 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 38.062,38.804 h 0.006 c -0.048,-0.079 -0.1,-0.152 -0.147,-0.231 0.087,0.144 0.141,0.231 0.141,0.231 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c -0.631,-0.197 -1.249,-0.424 -1.856,-0.669 -0.003,0.002 -0.007,0.003 -0.009,0.004 0.06,0.025 0.781,0.324 1.865,0.665 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 52.226,49.57 c 0.002,0 0.005,-0.002 0.007,-0.003 -0.106,-0.03 -0.213,-0.057 -0.318,-0.091 0.101,0.033 0.205,0.065 0.311,0.094 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 74.458,0.955 H 59.321 c -1.307,0 -2.591,0.1 -3.845,0.293 -0.273,0.042 -0.541,0.101 -0.811,0.151 4.646,2.666 8.469,6.605 10.987,11.343 h 1.238 8.346 c 7.322,0 13.257,5.937 13.257,13.259 0,7.321 -5.936,13.258 -13.257,13.258 H 65.72 63.762 61.857 61.851 58.68 c -3.305,0 -6.324,-1.212 -8.646,-3.212 0,0 -0.003,0.003 -0.003,0.003 0,-0.002 -10e-4,-0.002 -0.002,-0.003 -0.494,-0.414 -0.886,-0.802 -1.206,-1.148 -0.7,-0.764 -1.011,-1.303 -1.011,-1.303 0.001,-0.002 0.002,-0.002 0.002,-0.003 -10e-4,-0.001 -0.002,-0.002 -0.002,-0.003 -1.505,-2.15 -2.389,-4.766 -2.389,-7.589 0,-2.746 0.834,-5.296 2.263,-7.413 0.041,-0.06 0.086,-0.117 0.127,-0.176 -1.736,-1.473 -3.978,-2.367 -6.429,-2.367 h -5.041 c -1.325,3.052 -2.067,6.416 -2.067,9.956 0,3.538 0.737,6.903 2.061,9.955 0.244,0.561 0.509,1.111 0.792,1.651 0.237,0.45 0.482,0.896 0.746,1.332 0.02,0.033 0.036,0.059 0.054,0.088 0.047,0.079 0.099,0.152 0.147,0.231 2.792,4.463 6.948,7.98 11.888,9.973 0.608,0.245 1.226,0.472 1.856,0.669 0.034,0.011 0.068,0.022 0.103,0.031 0.105,0.034 0.212,0.061 0.318,0.091 0.27,0.08 0.541,0.161 0.815,0.232 0.004,0 0.006,0.002 0.01,0.003 2,0.513 4.096,0.787 6.254,0.787 H 74.457 C 88.289,51.044 99.501,39.831 99.501,26 99.502,12.169 88.29,0.955 74.458,0.955 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 25.542,51.045 h 15.137 c 1.308,0 2.592,-0.101 3.846,-0.294 0.273,-0.042 0.542,-0.1 0.811,-0.151 C 40.69,47.935 36.866,43.996 34.349,39.258 H 33.11 24.764 c -7.322,0 -13.257,-5.936 -13.257,-13.259 0,-7.322 5.935,-13.257 13.257,-13.257 h 9.516 1.957 1.905 0.007 3.17 c 3.304,0 6.323,1.212 8.645,3.212 l 0.002,-0.003 c 10e-4,10e-4 10e-4,0.002 0.002,0.003 0.495,0.413 0.887,0.801 1.206,1.148 0.701,0.762 1.011,1.302 1.011,1.302 0,0.001 -0.001,0.002 -0.002,0.003 10e-4,0 0.002,0.001 0.003,0.003 1.505,2.15 2.39,4.766 2.39,7.588 0,2.746 -0.835,5.297 -2.264,7.412 -0.041,0.062 -0.085,0.118 -0.127,0.176 1.736,1.474 3.979,2.369 6.429,2.369 h 5.042 c 1.324,-3.053 2.065,-6.417 2.065,-9.957 0,-3.539 -0.737,-6.903 -2.061,-9.955 C 63.416,15.482 63.151,14.932 62.868,14.392 62.631,13.941 62.386,13.494 62.122,13.06 62.102,13.027 62.086,13 62.069,12.971 62.021,12.893 61.97,12.818 61.922,12.741 59.13,8.278 54.973,4.76 50.034,2.768 49.426,2.523 48.808,2.297 48.178,2.098 48.144,2.087 48.11,2.077 48.075,2.066 47.97,2.034 47.863,2.007 47.757,1.977 47.487,1.896 47.216,1.815 46.941,1.745 46.937,1.744 46.935,1.744 46.932,1.743 44.932,1.228 42.837,0.955 40.677,0.955 H 25.542 c -13.832,0 -25.044,11.212 -25.044,25.044 0,13.833 11.212,25.046 25.044,25.046 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"M 53.058,49.803 C 53.055,49.802 53.052,49.8 53.048,49.8 c 0.004,0 0.007,0.002 0.01,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 51.812,49.445 c 0.034,0.011 0.068,0.022 0.103,0.031 -0.034,-0.008 -0.068,-0.02 -0.103,-0.031 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 47.805,33.141 c 0,0 0.311,0.539 1.011,1.303 0.005,-0.006 0.01,-0.012 0.016,-0.015 -0.369,-0.407 -0.709,-0.84 -1.025,-1.291 0,0.001 -0.001,0.001 -0.002,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 37.92,38.572 c -0.018,-0.029 -0.034,-0.055 -0.054,-0.088 0.019,0.03 0.036,0.058 0.054,0.088 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 48.832,34.429 c -0.006,0.003 -0.011,0.009 -0.016,0.015 0.319,0.347 0.711,0.734 1.206,1.148 0.001,-0.002 0.002,-0.003 0.002,-0.003 -0.42,-0.362 -0.82,-0.749 -1.192,-1.16 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"path\", {\n    parentName: \"g\",\n    \"d\": \"m 50.027,35.592 c 10e-4,-0.003 0.004,-0.006 0.012,-0.015 -0.004,0.004 -0.01,0.008 -0.015,0.012 10e-4,0 0.002,0.001 0.003,0.003 z\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }), mdx(\"rect\", {\n    parentName: \"g\",\n    \"height\": \"0.004007bff2\",\n    \"width\": \"0.004007bff2\",\n    \"y\": \"35.59\",\n    \"x\": \"50.021999\",\n    \"style\": {},\n    \"fill\": \"#007bff\"\n  }))))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://netflixtechblog.com/artwork-personalization-c589f074ad76\"\n  }, \"Artwork Personalization at Netflix\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://doordash.engineering/2020/01/27/personalized-cuisine-filter/\"\n  }, \"Personalized Cuisine Filter\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1003.0146\"\n  }, \"A Contextual-Bandit Approach to Personalized News Article\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1003.0120\"\n  }, \"Learning from Logged Implicit Exploration Data\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/3240323.3240354\"\n  }, \"Explore, Exploit, and Explain: Personalizing Explainable Recommendations\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://dl.acm.org/doi/10.1145/3394486.3403374\"\n  }, \"Bandit based Optimization of Multiple Objectives on a Music Streaming Platform\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2009.06546\"\n  }, \"Carousel Personalization in Music Streaming Apps with Contextual Bandits\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.09368\"\n  }, \"Contextual User Browsing Bandits for Mobile Recommendations\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1810.09558\"\n  }, \"An Efficient Bandit Algorithm for Realtime Multivariate Optimization\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.00727\"\n  }, \"Deep Bayesian Bandits: Exploring in Online Personalized Recommendations\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1809.02130\"\n  }, \"Deep Neural Network Marketplace Recommenders in Online Experiments\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://papers.nips.cc/paper/2011/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html\"\n  }, \"An Empirical Evaluation of Thompson Sampling\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1003.5956\"\n  }, \"Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms\"))));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"slug":"/resources/bandits/"}},
    "staticQueryHashes": ["3159585216","3897982121"]}